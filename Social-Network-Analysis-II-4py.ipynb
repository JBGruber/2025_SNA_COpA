{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Social Network Analysis 2\n",
        "\n",
        "COST Action Training School in Computational Opinion Analysis – COpA\n",
        "\n",
        "Johannes B. Gruber \\| GESIS\n",
        "\n",
        "# Example: Divided They Blog\n",
        "\n",
        "## Packages and setup"
      ],
      "id": "84c02772-4f13-401b-a8e9-ee3a3aa2afb9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import igraph as ig\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.lines import Line2D\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "import imageio.v2 as imageio\n",
        "from tqdm import tqdm\n",
        "import leidenalg\n",
        "from atproto import Client, models\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from itertools import combinations\n",
        "import math"
      ],
      "id": "e3a13ca9-48e4-4049-bf04-a84e446246b8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Blogosphere data"
      ],
      "id": "58938dc0-27f1-4d81-9218-f84bb18c44d2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph_file = \"data/polblogs.zip\"\n",
        "os.makedirs(os.path.dirname(graph_file), exist_ok=True)\n",
        "\n",
        "if not os.path.exists(graph_file):\n",
        "    print(\"Downloading polblogs.zip file...\")\n",
        "    url = \"https://public.websites.umich.edu/~mejn/netdata/polblogs.zip\"\n",
        "    response = requests.get(url)\n",
        "    with open(graph_file, 'wb') as f:\n",
        "        f.write(response.content)\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "# have a quick look at the data description\n",
        "with zipfile.ZipFile(graph_file, 'r') as zip_ref:\n",
        "    with zip_ref.open('polblogs.txt') as f:\n",
        "        print(f.read().decode('utf-8'))"
      ],
      "id": "b6b4a32d-fafe-4430-b35f-17e4e32766d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## graph data structure in `R`\n",
        "\n",
        "Let’s first look at the `igraph` graph class:"
      ],
      "id": "c460c264-69ef-4c9e-b38e-59b61c7bd979"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(graph_file, 'r') as zip_ref:\n",
        "    with zip_ref.open('polblogs.gml') as f:\n",
        "        gml_content = f.read().decode('utf-8')\n",
        "        with open(\"data/polblogs.gml\", 'w') as f:\n",
        "            f.write(gml_content)\n",
        "\n",
        "polblogs_ig = ig.Graph.Read_GML(\"data/polblogs.gml\")\n",
        "\n",
        "print(type(polblogs_ig))\n",
        "print(polblogs_ig.summary())"
      ],
      "id": "fa83b752-0b4b-4073-891f-bc3a33ce4b13"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## graph data structure in `R`\n",
        "\n",
        "We can convert this to a `tidygraph` object:"
      ],
      "id": "c1ad712e-380e-45d6-afa7-bb7ca01cf13a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Python equivalent using NetworkX for tidygraph-like functionality\n",
        "polblogs_nx = ig.Graph.to_networkx(polblogs_ig)\n",
        "print(type(polblogs_nx))\n",
        "print(f\"NetworkX Graph with {polblogs_nx.number_of_nodes()} nodes and {polblogs_nx.number_of_edges()} edges\")\n",
        "print(f\"Directed: {polblogs_nx.is_directed()}\")"
      ],
      "id": "9d1ae921-f360-42f4-b76a-87af7bdf3bec"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## graph data structure in `R`/`Python`\n",
        "\n",
        "Both `igraph` and `tbl_graph` objects essentially consist of two linked\n",
        "tables containing <span class=\"kn-pink\">nodes</span> (aka vertices) and\n",
        "<span class=\"kn-pink\">edges</span>."
      ],
      "id": "7ff97036-2111-4b8b-a341-bd32ca1eba36"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nodes_df = pd.DataFrame({\n",
        "    'id': range(polblogs_ig.vcount()),\n",
        "    'value': polblogs_ig.vs['value'],\n",
        "    'name': polblogs_ig.vs['label']\n",
        "})\n",
        "print(\"\\nNodes:\")\n",
        "print(nodes_df.head())"
      ],
      "id": "cbf723ae-38ea-4a37-bd0e-69954008f51d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "edges_df = pd.DataFrame({\n",
        "    'from': [e.source for e in polblogs_ig.es],\n",
        "    'to': [e.target for e in polblogs_ig.es]\n",
        "})\n",
        "print(\"\\nEdges:\")\n",
        "print(edges_df.head())"
      ],
      "id": "8f863202-63d7-4096-a60b-2bc68bbb357d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## working with graph data structures in `R`\n",
        "\n",
        "We can look up the variables (like political class) for any given node\n",
        "by filtering. For example, let’s see the node with ID 30:"
      ],
      "id": "04f562fb-e7a4-4d06-a8ff-79d23034199e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for vertex in polblogs_ig.vs:\n",
        "    if vertex['id'] == 30:\n",
        "        print(vertex)"
      ],
      "id": "acf06415-1924-4ad3-a1a3-0dec10d1e016"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## working with graph data structures in `R`\n",
        "\n",
        "If we want to see how many left and right blogs are in the data, we can\n",
        "use `count`. But only after converting the nodes to a `data.frame`!"
      ],
      "id": "62df3e1c-9a79-4b1b-a593-ed95fb78f211"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "left_blogs = []\n",
        "right_blogs = []\n",
        "for vertex in polblogs_ig.vs:\n",
        "    if vertex['value'] == 0:\n",
        "        left_blogs.append(vertex)\n",
        "    else:\n",
        "        right_blogs.append(vertex)\n",
        "\n",
        "print(f\"{len(left_blogs)} left blogs\")\n",
        "print(f\"{len(right_blogs)} right blogs\")"
      ],
      "id": "28bbe9bb-b8cb-4a37-bd71-86e79b6de56b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## working with graph data structures in `R`\n",
        "\n",
        "The `value` variable is named terribly and stored in a strange format.\n",
        "Let’s change that using some more tidyverse functions that work\n",
        "out-of-the-box with `tidygraph` graphs:"
      ],
      "id": "f33e1321-70fa-4115-8857-4201d9967dc1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ideology = []\n",
        "for vertex in polblogs_ig.vs:\n",
        "    if vertex['value'] == 0:\n",
        "        ideology.append(\"left\")\n",
        "    else:\n",
        "        ideology.append(\"right\")\n",
        "\n",
        "polblogs_ig.vs['ideology'] = ideology\n",
        "\n",
        "print(polblogs_ig.vs[1])"
      ],
      "id": "c02657e8-c2a5-4ae1-b7d2-939d79792539"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It’s not necessary to store ideology as a factor, but generally good\n",
        "practice in `R`. Whenever you have a variable with just a few repeating\n",
        "character values, a factor is more efficient.\n",
        "\n",
        "## first insights\n",
        "\n",
        "We can answer some initial questions about the data:\n",
        "\n",
        "-   how many left and right blogs are there?"
      ],
      "id": "1c75614c-e85c-4979-bb02-d90f4215254e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "polblogs_ig.vs['ideology'].count('left')\n",
        "polblogs_ig.vs['ideology'].count('right')"
      ],
      "id": "45173f6a-af95-42bf-bd7b-b6043201ef13"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## first insights\n",
        "\n",
        "We can answer some initial questions about the data:\n",
        "\n",
        "-   how many connections (edges) do nodes have to other nodes?"
      ],
      "id": "e2159273-7c5f-437f-acc3-c2510ec07117"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from_counts = edges_df['from'].value_counts().head(10)\n",
        "print(\"Top nodes by outgoing connections:\")\n",
        "print(from_counts)"
      ],
      "id": "b3da85ce-4b70-4369-a882-12f62f802a0a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s have a closer look at the top node:"
      ],
      "id": "57bc5330-eed5-4cc6-ab96-b77ccca11e5a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(nodes_df[nodes_df['id'] == 854])"
      ],
      "id": "a6e7374b-ed73-49cc-bbfb-0d2dfbcd876c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "to_counts = edges_df['to'].value_counts().head(10)\n",
        "print(\"\\nTop nodes by incoming connections:\")\n",
        "print(to_counts)"
      ],
      "id": "ba383a03-5781-4e82-9eb7-dda0c9eb20cf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s have a closer look at the top node:"
      ],
      "id": "c89739e7-a205-4d0b-a35c-d24583b43119"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(nodes_df[nodes_df['id'] == 154])"
      ],
      "id": "b14b20be-b0b0-431b-a51b-699a3cd918e6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## first insights\n",
        "\n",
        "We can answer some initial questions about the data:\n",
        "\n",
        "-   do left and right blogs reference each other?"
      ],
      "id": "ca0698e8-3268-4137-b01b-217fc5551c10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nodes_df = pd.DataFrame({\n",
        "    'id': range(polblogs_ig.vcount()),\n",
        "    'value': polblogs_ig.vs['value'],\n",
        "    'name': polblogs_ig.vs['label'],\n",
        "    'ideology': polblogs_ig.vs['ideology']\n",
        "}) \n",
        "\n",
        "# Map ideology to from and to nodes\n",
        "edges_df['from_ideo'] = edges_df['from'].map(nodes_df['ideology'])\n",
        "edges_df['to_ideo'] = edges_df['to'].map(nodes_df['ideology'])\n",
        "\n",
        "# Count combinations of from_ideo and to_ideo\n",
        "print(edges_df.groupby(['from_ideo', 'to_ideo']).size().reset_index(name='n'))"
      ],
      "id": "ee3edb6d-e442-4c87-954b-6f0ca6483175"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## visualising graphs in `R`\n",
        "\n",
        "-   `ggraph` inherits the idea of a grammar of graphics from `ggplot`\n",
        "-   hence, we build up plots in layers with visual aesthetics mapped to\n",
        "    data\n",
        "-   the difference is, we address map data from the nodes and edges\n",
        "    table\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://ggraph.data-imaginist.com/reference/figures/logo.png\"\n",
        "alt=\"ggraph\" />\n",
        "<figcaption aria-hidden=\"true\">ggraph</figcaption>\n",
        "</figure>\n",
        "\n",
        "## visualising graphs in `Python`\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://networkx.org/_static/networkx_logo.svg\"\n",
        "alt=\"NetworkX\" />\n",
        "<figcaption aria-hidden=\"true\">NetworkX</figcaption>\n",
        "</figure>\n",
        "\n",
        "-   Basic network visualization using NetworkX and matplotlib"
      ],
      "id": "c0edccc4-293e-4261-a893-58b78b469188"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Get node colors based on ideology\n",
        "node_colors = ['#2F357E' if polblogs_ig.vs[i]['ideology'] == 'left' else '#D72F32'\n",
        "               for i in range(len(polblogs_ig.vs))]\n",
        "\n",
        "nx.draw_kamada_kawai(polblogs_nx, with_labels=False, node_color=node_colors)\n",
        "plt.show()"
      ],
      "id": "4f0480c8-1470-4547-9ff6-e41fd598130c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recreate the plot from Adamic and Glance (2005)"
      ],
      "id": "790e1f20-755c-49d7-aca5-9dd71da5d61b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Calculate in-degree centrality (referenced)\n",
        "in_degrees = polblogs_nx.in_degree()\n",
        "referenced = {node: degree for node, degree in in_degrees}\n",
        "\n",
        "# Remove isolated nodes\n",
        "non_isolated_nodes = [node for node in polblogs_nx.nodes() if polblogs_nx.degree(node) > 0]\n",
        "subgraph = polblogs_nx.subgraph(non_isolated_nodes)\n",
        "\n",
        "# Prepare edge colors based on ideology connections\n",
        "edge_colors = []\n",
        "for edge in subgraph.edges():\n",
        "    from_node, to_node = edge\n",
        "    from_ideo = polblogs_ig.vs[from_node]['ideology']\n",
        "    to_ideo = polblogs_ig.vs[to_node]['ideology']\n",
        "    \n",
        "    if from_ideo == \"left\" and to_ideo == \"left\":\n",
        "        edge_colors.append(\"#2F357E\")\n",
        "    elif from_ideo == \"right\" and to_ideo == \"right\":\n",
        "        edge_colors.append(\"#D72F32\")\n",
        "    else:  # bipartisan connections\n",
        "        edge_colors.append(\"#f4c23b\")\n",
        "\n",
        "# Prepare node properties\n",
        "node_colors = ['#2F357E' if polblogs_ig.vs[node]['ideology'] == 'left' else '#D72F32' \n",
        "               for node in subgraph.nodes()]\n",
        "node_sizes = [referenced.get(node, 1) * 10 + 20 for node in subgraph.nodes()]\n",
        "\n",
        "# Draw the network\n",
        "nx.draw_kamada_kawai(subgraph, with_labels=False, node_color=node_colors,\n",
        "                     edge_color=edge_colors)\n",
        "\n",
        "plt.show()"
      ],
      "id": "4e15e8d5-1b54-459a-8cc8-ceab01ef7df6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## volatile layouts\n",
        "\n",
        "One thing that always makes me cautious about interpreting network plots\n",
        "is how volatile the placement of nodes in the plot is and how much it\n",
        "can trick you into finding a pattern where none exists. So let’s look at\n",
        "an experiment:\n",
        "\n",
        "Prepare data for plotting:"
      ],
      "id": "b3bbabba-6324-4cb4-a846-3ad4e50895d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "# Sample 25% of nodes randomly for faster plotting\n",
        "sample_size = int(0.25 * polblogs_nx.number_of_nodes())\n",
        "sampled_nodes = np.random.choice(list(polblogs_nx.nodes()), size=sample_size, replace=False)\n",
        "plot_subgraph = polblogs_nx.subgraph(sampled_nodes)\n",
        "\n",
        "# Remove isolated nodes\n",
        "non_isolated = [node for node in plot_subgraph.nodes() if plot_subgraph.degree(node) > 0]\n",
        "plot_subgraph = plot_subgraph.subgraph(non_isolated)\n",
        "\n",
        "# Calculate referenced (in-degree)\n",
        "in_degrees_sample = plot_subgraph.in_degree()"
      ],
      "id": "74a2e37a-7290-409d-9acd-3a175667dc2a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get all available layouts:"
      ],
      "id": "2b613219-aa0e-4c69-842c-302bf097c61c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nx_layouts = {\n",
        "    'circular': nx.circular_layout,\n",
        "    'random': nx.random_layout,\n",
        "    'shell': nx.shell_layout,\n",
        "    'spring': nx.spring_layout,\n",
        "    'kamada_kawai': nx.kamada_kawai_layout,\n",
        "    'planar': nx.planar_layout,\n",
        "    'spectral': nx.spectral_layout\n",
        "}"
      ],
      "id": "1fa28364-960f-4360-9904-1a74c6502aa4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## volatile layouts"
      ],
      "id": "ec6e5587-8919-4eaa-b84d-bba069307956"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create plots with different layouts to show volatility\n",
        "os.makedirs(\"media/layouts_py/\", exist_ok=True)\n",
        "\n",
        "def create_network_plot(subgraph, layout_func, layout_name, save_path):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    \n",
        "    try:\n",
        "        if layout_name == 'planar':\n",
        "            # Check if graph is planar\n",
        "            if nx.is_planar(subgraph):\n",
        "                pos = layout_func(subgraph)\n",
        "            else:\n",
        "                pos = nx.spring_layout(subgraph)  # fallback\n",
        "        else:\n",
        "            pos = layout_func(subgraph)\n",
        "    except:\n",
        "        pos = nx.spring_layout(subgraph)  # fallback for any errors\n",
        "    \n",
        "    # Prepare edge colors\n",
        "    edge_colors = []\n",
        "    for edge in subgraph.edges():\n",
        "        from_node, to_node = edge\n",
        "        if from_node < len(polblogs_ig.vs) and to_node < len(polblogs_ig.vs):\n",
        "            from_ideo = polblogs_ig.vs[from_node]['ideology']\n",
        "            to_ideo = polblogs_ig.vs[to_node]['ideology']\n",
        "            \n",
        "            if from_ideo == \"left\" and to_ideo == \"left\":\n",
        "                edge_colors.append(\"#2F357E\")\n",
        "            elif from_ideo == \"right\" and to_ideo == \"right\":\n",
        "                edge_colors.append(\"#D72F32\")\n",
        "            else:\n",
        "                edge_colors.append(\"#f4c23b\")\n",
        "        else:\n",
        "            edge_colors.append(\"#gray\")\n",
        "    \n",
        "    # Prepare node properties\n",
        "    node_colors = []\n",
        "    node_sizes = []\n",
        "    for node in subgraph.nodes():\n",
        "        if node < len(polblogs_ig.vs):\n",
        "            ideology = polblogs_ig.vs[node]['ideology']\n",
        "            node_colors.append('#2F357E' if ideology == 'left' else '#D72F32')\n",
        "            node_sizes.append(in_degrees_sample.get(node, 1) * 20 + 30)\n",
        "        else:\n",
        "            node_colors.append('gray')\n",
        "            node_sizes.append(30)\n",
        "    \n",
        "    # Draw network\n",
        "    nx.draw_kamada_kawai(subgraph, with_labels=False, node_color=node_colors,\n",
        "                         edge_color=edge_colors)\n",
        "    # nx.draw_networkx_edges(subgraph, pos, edge_color=edge_colors, alpha=0.6, \n",
        "    #                       width=0.5, arrows=True, arrowsize=8)\n",
        "    # nx.draw_networkx_nodes(subgraph, pos, node_color=node_colors, \n",
        "    #                       node_size=node_sizes, alpha=0.8, edgecolors='black')\n",
        "    \n",
        "    plt.title(f\"Layout: {layout_name}\", fontsize=14)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# Generate plots for different layouts\n",
        "layout_files = []\n",
        "for layout_name, layout_func in nx_layouts.items():\n",
        "    plot_path = f\"media/layouts_py/network_{layout_name}.png\"\n",
        "    print(plot_path)\n",
        "    create_network_plot(plot_subgraph, layout_func, layout_name, plot_path)\n",
        "    layout_files.append(plot_path)\n",
        "    print(f\"Created plot with {layout_name} layout\")\n",
        "\n",
        "# Create GIF from the images\n",
        "if layout_files:\n",
        "    images = [imageio.imread(f) for f in layout_files if os.path.exists(f)]\n",
        "    if images:\n",
        "        imageio.mimsave(\"media/layouts_python.gif\", images, duration=1.5)\n",
        "        print(\"Created animated GIF showing layout volatility\")"
      ],
      "id": "d814a6cc-2a44-4559-a431-afd0bf706dcc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## community detection\n",
        "\n",
        "In the previous figure we used the political orientation of blogs\n",
        "manually assigned by Adamic and Glance (2005). Usually, we want to\n",
        "detect communities from the network structure itself. We learned about\n",
        "the <span class=\"kn-pink\">Louvain</span> and\n",
        "<span class=\"kn-pink\">Leiden</span> algorithms (and about their\n",
        "downsides). So let’s start with these."
      ],
      "id": "e97254ea-195b-4faa-958b-7c17310ef4ec"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Community detection using Louvain and Leiden algorithms\n",
        "import leidenalg\n",
        "import networkx.algorithms.community as nx_comm\n",
        "\n",
        "# Convert to undirected graph for community detection\n",
        "polblogs_undirected = polblogs_nx.to_undirected()\n",
        "\n",
        "# Louvain community detection using NetworkX\n",
        "louvain_communities = nx_comm.louvain_communities(polblogs_undirected, seed=42)\n",
        "\n",
        "# Create group assignments for Louvain\n",
        "group_louvain = {}\n",
        "for i, community in enumerate(louvain_communities):\n",
        "    for node in community:\n",
        "        group_louvain[node] = i\n",
        "\n",
        "# Leiden community detection using igraph and leidenalg\n",
        "leiden_partition = leidenalg.find_partition(polblogs_ig, leidenalg.ModularityVertexPartition)\n",
        "\n",
        "# Create group assignments for Leiden\n",
        "group_leiden = {}\n",
        "for i, community in enumerate(leiden_partition):\n",
        "    for node in community:\n",
        "        group_leiden[node] = i\n",
        "\n",
        "# Add community assignments to nodes dataframe\n",
        "nodes_df['group_louvain'] = nodes_df['id'].map(group_louvain)\n",
        "nodes_df['group_leiden'] = nodes_df['id'].map(group_leiden)\n",
        "\n",
        "print(\"Nodes with community assignments:\")\n",
        "print(nodes_df.head(10))\n",
        "\n",
        "print(f\"\\nNumber of Louvain communities: {len(louvain_communities)}\")\n",
        "print(f\"Number of Leiden communities: {len(set(leiden_partition.membership))}\")"
      ],
      "id": "4142a420-7682-4ad9-8446-f5541ed4f03f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## community detection"
      ],
      "id": "7080b724-a366-4594-b793-eb0a007f16ad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot network with Louvain communities\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Create layout\n",
        "non_isolated_nodes = [node for node in polblogs_undirected.nodes() if polblogs_undirected.degree(node) > 0]\n",
        "subgraph_undirected = polblogs_undirected.subgraph(non_isolated_nodes[1:100])\n",
        "# pos = nx.draw_kamada_kawai(subgraph_undirected)\n",
        "\n",
        "# Prepare node colors based on Louvain communities\n",
        "louvain_colors = plt.cm.Set3(np.linspace(0, 1, len(louvain_communities)))\n",
        "node_colors_louvain = []\n",
        "for node in subgraph_undirected.nodes():\n",
        "    community_id = group_louvain.get(node, 0)\n",
        "    node_colors_louvain.append(louvain_colors[community_id % len(louvain_colors)])\n",
        "\n",
        "# Prepare node sizes based on in-degree\n",
        "in_degrees_full = polblogs_nx.in_degree()\n",
        "\n",
        "# Draw the network\n",
        "nx.draw_kamada_kawai(subgraph_undirected, edge_color='black',\n",
        "                     width=0.2, arrows=True, arrowsize=8, arrowstyle='->',\n",
        "                     node_color=node_colors_louvain)\n",
        "\n",
        "plt.title(\"Blogosphere grouped by Louvain\", fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "5bd2a4a3-963a-4a5c-a444-dc7ee4d798ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## community detection"
      ],
      "id": "773f2626-4eaa-431f-ab62-c944ee00aaba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot network with Leiden communities\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Use the same layout as before for comparison\n",
        "pos = nx.draw_kamada_kawai(subgraph_undirected)\n",
        "\n",
        "# Prepare node colors based on Leiden communities\n",
        "n_leiden_communities = len(set(leiden_partition.membership))\n",
        "leiden_colors = plt.cm.Set1(np.linspace(0, 1, n_leiden_communities))\n",
        "node_colors_leiden = []\n",
        "for node in subgraph_undirected.nodes():\n",
        "    community_id = group_leiden.get(node, 0)\n",
        "    node_colors_leiden.append(leiden_colors[community_id % len(leiden_colors)])\n",
        "\n",
        "# Use same node sizes as before\n",
        "# node_sizes_leiden = [in_degrees_full.get(node, 1) * 15 + 30 for node in subgraph_undirected.nodes()]\n",
        "\n",
        "# Draw the network\n",
        "nx.draw_networkx_edges(subgraph_undirected, pos, edge_color='gray', alpha=0.3, width=0.2,\n",
        "                      arrows=True, arrowsize=8, arrowstyle='->')\n",
        "nx.draw_networkx_nodes(subgraph_undirected, pos, node_color=node_colors_leiden, \n",
        "                       alpha=0.8, edgecolors='black', linewidths=0.5)\n",
        "\n",
        "plt.title(\"Blogosphere grouped by Leiden\", fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "53b9cbc5-943e-442f-859e-9ed5f08a6f99"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bluesky: What is my Bluesky network?\n",
        "\n",
        "Before we start working with Bluesky, you should authenticate your\n",
        "session:"
      ],
      "id": "1d8f628c-a29e-4a95-882a-11e1fdf78704"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = Client()\n",
        "client.login('jbgruber.bsky.social', '4srg-qdme-rgsr-cmal')"
      ],
      "id": "b841bf12-55f8-4b9f-837c-ceaccbbd244a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When you are new to Bluesky you should start by searching a few names\n",
        "that you know. There are also starter packs like\n",
        "<https://bsky.app/starter-pack/sof14g1l.bsky.social/3lbc4bqetfp22> which\n",
        "you can follow. But what then? Given the idea of homophily, you might\n",
        "want to check who the people you follow, follow themselves. So let’s get\n",
        "started with that (replace my handle with yours below if you like):"
      ],
      "id": "085eb564-266e-43ef-a749-92b022b4db85"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get my follows (replace with your handle)\n",
        "def get_follows_data(handle, limit=None):\n",
        "    \"\"\"Get follows for a given handle\"\"\"\n",
        "    try:\n",
        "        response = client.get_follows(handle, limit=limit)\n",
        "        follows_data = []\n",
        "        for follow in response.follows:\n",
        "            follows_data.append({\n",
        "                'actor_handle': follow.handle,\n",
        "                'actor_did': follow.did,\n",
        "                'actor_display_name': follow.display_name or ''\n",
        "            })\n",
        "        return pd.DataFrame(follows_data)\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting follows for {handle}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "my_follows = get_follows_data(\"jbgruber.bsky.social\")\n",
        "print(f\"Shape of my_follows: {my_follows.shape}\")\n",
        "print(my_follows.head())"
      ],
      "id": "d1db0054-d687-42af-9c01-22885b377bd7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we want to see who they follow:"
      ],
      "id": "06721c00-784d-4154-af69-dacfdb2a48d2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_their_follows(handles, limit=100):\n",
        "    \"\"\"Get follows for multiple handles\"\"\"\n",
        "    their_follows = []\n",
        "    \n",
        "    for handle in tqdm(handles, desc=\"Getting follows\"):\n",
        "        follows_df = get_follows_data(handle, limit=limit)\n",
        "        if not follows_df.empty:\n",
        "            follows_df['from'] = handle\n",
        "            follows_df['to'] = follows_df['actor_handle']\n",
        "            their_follows.append(follows_df[['from', 'to']])\n",
        "    \n",
        "    return pd.concat(their_follows, ignore_index=True) if their_follows else pd.DataFrame()\n",
        "\n",
        "# Save/load data to avoid repeated API calls\n",
        "their_follows_file = \"data/their_follows_py.pkl\"\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "if not os.path.exists(their_follows_file):\n",
        "    # Take last 50 accounts I followed\n",
        "    recent_follows = my_follows['actor_handle'].tail(50).tolist()\n",
        "    their_follows = get_their_follows(recent_follows)\n",
        "    \n",
        "    with open(their_follows_file, 'wb') as f:\n",
        "        pickle.dump(their_follows, f)\n",
        "else:\n",
        "    with open(their_follows_file, 'rb') as f:\n",
        "        their_follows = pickle.load(f)\n",
        "\n",
        "print(f\"Shape of their_follows: {their_follows.shape}\")\n",
        "print(their_follows.head())"
      ],
      "id": "c0088b36-1690-463b-a791-73272544a0fc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a first step, we can just check the raw number of who shows up most\n",
        "often here:"
      ],
      "id": "6373e06f-d118-4806-bed2-4a2cac2aa822"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check raw counts of who shows up most often\n",
        "follow_counts = their_follows['to'].value_counts()\n",
        "follow_counts = follow_counts[follow_counts.index != 'handle.invalid']\n",
        "top_15 = follow_counts.head(15)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(top_15)), top_15.values)\n",
        "plt.yticks(range(len(top_15)), top_15.index)\n",
        "plt.xlabel('Count')\n",
        "plt.title('Most Followed Accounts')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "77f1b981-517e-4350-ae6f-8d815c987a48"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "But we can also use network analysis to find influential accounts:"
      ],
      "id": "5ba43ea7-6555-4286-8e49-ee783bf9222b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create network graph\n",
        "follows_graph = nx.from_pandas_edgelist(their_follows, 'from', 'to', create_using=nx.DiGraph())\n",
        "\n",
        "# Calculate centrality measures\n",
        "degree_centrality = nx.degree_centrality(follows_graph)\n",
        "closeness_centrality = nx.closeness_centrality(follows_graph)\n",
        "betweenness_centrality = nx.betweenness_centrality(follows_graph)\n",
        "eigenvector_centrality = nx.eigenvector_centrality(follows_graph, max_iter=1000)\n",
        "\n",
        "# Create centrality dataframe\n",
        "centrality_df = pd.DataFrame({\n",
        "    'name': list(follows_graph.nodes()),\n",
        "    'degree': [degree_centrality[node] for node in follows_graph.nodes()],\n",
        "    'closeness': [closeness_centrality[node] for node in follows_graph.nodes()],\n",
        "    'betweenness': [betweenness_centrality[node] for node in follows_graph.nodes()],\n",
        "    'eigenvector': [eigenvector_centrality[node] for node in follows_graph.nodes()]\n",
        "})"
      ],
      "id": "4add0e51-a575-475f-9141-0d2bc4ae46e5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at **degree** centrality (simply counts the number of\n",
        "neighbors a node has):"
      ],
      "id": "fd1b74cf-4a04-433e-9e5b-b33693bb4106"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Top 10 by degree centrality:\")\n",
        "print(centrality_df.nlargest(10, 'degree')[['name', 'degree']])"
      ],
      "id": "fe50ee4e-b5ae-4041-aeea-e7392667b38f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**closeness** (computes the shortest path distances among nodes. The\n",
        "most central node has the minimum distance to all other nodes)"
      ],
      "id": "a5e08471-b794-43ba-8b14-5e71071730e9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Top 10 by closeness centrality:\")\n",
        "print(centrality_df.nlargest(10, 'closeness')[['name', 'closeness']])"
      ],
      "id": "ccb5a528-5fe9-4209-8777-9c6c2b756289"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**betweeness** (number of shortest paths that pass through a node,\n",
        "divided by the total number of shortest paths)"
      ],
      "id": "37eb1705-19f9-4886-9c28-5ac6bdbf55af"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Top 10 by betweenness centrality:\")\n",
        "central_accounts = centrality_df.nlargest(10, 'betweenness')\n",
        "print(central_accounts[['name', 'betweenness']])"
      ],
      "id": "e065db6a-d751-4429-8340-30b22997e658"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and **eigenvector centrality** (extends the idea of degree by assuming\n",
        "that a node is central if it is connected to other central nodes)"
      ],
      "id": "8ab2d8a3-6090-4b7c-91ec-bbc7137ed709"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Top 10 by eigenvector centrality:\")\n",
        "print(centrality_df.nlargest(10, 'eigenvector')[['name', 'eigenvector']])"
      ],
      "id": "b0c743a2-6a74-406a-969f-881330be47b2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also visialise this network and highlight some of the accounts in\n",
        "it:"
      ],
      "id": "8eafdc82-83a5-4ee2-b173-fa3e39eaab58"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create network visualization highlighting central accounts\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Get top 500 nodes by eigenvector centrality for visualization\n",
        "top_nodes = centrality_df.nlargest(500, 'eigenvector')['name'].tolist()\n",
        "subgraph = follows_graph.subgraph(top_nodes)\n",
        "\n",
        "# Get central accounts for highlighting\n",
        "central_account_names = central_accounts['name'].tolist()\n",
        "\n",
        "# Create layout\n",
        "pos = nx.spring_layout(subgraph, k=1, iterations=50)\n",
        "\n",
        "# Draw edges\n",
        "nx.draw_networkx_edges(subgraph, pos, alpha=0.3, width=0.5, edge_color='gray')\n",
        "\n",
        "# Draw nodes\n",
        "node_colors = ['firebrick' if node in central_account_names else 'lightblue' \n",
        "               for node in subgraph.nodes()]\n",
        "node_sizes = [centrality_df[centrality_df['name'] == node]['betweenness'].iloc[0] * 3000 + 50 \n",
        "              for node in subgraph.nodes()]\n",
        "\n",
        "nx.draw_networkx_nodes(subgraph, pos, node_color=node_colors, node_size=node_sizes, alpha=0.8)\n",
        "\n",
        "# Add labels for central accounts\n",
        "labels = {node: node if node in central_account_names else '' for node in subgraph.nodes()}\n",
        "nx.draw_networkx_labels(subgraph, pos, labels, font_size=8)\n",
        "\n",
        "plt.title('Network of Follows (Central Accounts Highlighted)', fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "4fd21ba8-6db3-4725-9120-0bd137f26c54"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For a different approach to find people to follow, you can check out\n",
        "<https://www.johannesbgruber.eu/post/2024-11-24-bluesky-rising/>.\n",
        "\n",
        "# Bluesky: Checking out the #rstats network\n",
        "\n",
        "First let’s get some data. The code below searches for posts that\n",
        "mention the hashtag #rstats, which is widely use for all things R:"
      ],
      "id": "97372fe0-4f9c-43bd-ae70-d4712c271752"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def search_posts(query, since_date=None, limit=None):\n",
        "    \"\"\"Search for posts with specific query using pagination\"\"\"\n",
        "    posts_data = []\n",
        "    total_limit = limit or 100\n",
        "    req_limit = min(total_limit, 100)  # API max is 100 per request\n",
        "    cursor = None\n",
        "    \n",
        "    try:\n",
        "        while len(posts_data) < total_limit:\n",
        "            # Adjust request limit for final batch\n",
        "            current_limit = min(req_limit, total_limit - len(posts_data))\n",
        "            \n",
        "            # Prepare search parameters\n",
        "            search_params = {\n",
        "                'q': query,\n",
        "                'limit': current_limit\n",
        "            }\n",
        "            \n",
        "            # Add cursor for pagination if available\n",
        "            if cursor:\n",
        "                search_params['cursor'] = cursor\n",
        "            \n",
        "            # Add since date if provided\n",
        "            if since_date:\n",
        "                search_params['since'] = since_date\n",
        "            \n",
        "            # Make API call\n",
        "            response = client.app.bsky.feed.search_posts(search_params)\n",
        "            \n",
        "            # Extract posts from response\n",
        "            if hasattr(response, 'posts') and response.posts:\n",
        "                for post in response.posts:\n",
        "                    # Extract hashtags from text\n",
        "                    hashtags = re.findall(r'#\\w+', post.record.text.lower())\n",
        "                    \n",
        "                    posts_data.append({\n",
        "                        'cid': post.cid,\n",
        "                        'uri': post.uri,\n",
        "                        'author_handle': post.author.handle,\n",
        "                        'text': post.record.text,\n",
        "                        'tags': hashtags,\n",
        "                        'reply_count': getattr(post, 'reply_count', 0) or 0,\n",
        "                        'repost_count': getattr(post, 'repost_count', 0) or 0,\n",
        "                        'like_count': getattr(post, 'like_count', 0) or 0\n",
        "                    })\n",
        "            else:\n",
        "                # No more posts available\n",
        "                break\n",
        "            \n",
        "            # Get cursor for next batch\n",
        "            if hasattr(response, 'cursor') and response.cursor:\n",
        "                cursor = response.cursor\n",
        "            else:\n",
        "                # No more pages available\n",
        "                break\n",
        "            \n",
        "            # Optional: show progress\n",
        "            if len(posts_data) % 100 == 0:\n",
        "                print(f\"Retrieved {len(posts_data)} posts so far...\")\n",
        "        \n",
        "        print(f\"Total posts retrieved: {len(posts_data)}\")\n",
        "        return pd.DataFrame(posts_data)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error searching posts: {e}\")\n",
        "        print(f\"Retrieved {len(posts_data)} posts before error\")\n",
        "        return pd.DataFrame(posts_data) if posts_data else pd.DataFrame()\n",
        "\n",
        "# Save/load data\n",
        "rstats_content_file = \"data/rstats_content_py.pkl\"\n",
        "\n",
        "if not os.path.exists(rstats_content_file):\n",
        "    rstats_content = search_posts(\"#rstats\", since_date=\"2025-04-01T00:00:00.000Z\", limit=math.inf)\n",
        "    with open(rstats_content_file, 'wb') as f:\n",
        "        pickle.dump(rstats_content, f)\n",
        "else:\n",
        "    with open(rstats_content_file, 'rb') as f:\n",
        "        rstats_content = pickle.load(f)\n",
        "\n",
        "print(f\"Shape of rstats_content: {rstats_content.shape}\")\n",
        "print(rstats_content.head())"
      ],
      "id": "df4624ea-9cbb-4342-9b09-28e05c2ff6b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Semantic Network/Co-hashtag Network\n",
        "\n",
        "The first network we can build from this data is a co-occurence network.\n",
        "We check, which hashtags are used together in these posts. In other\n",
        "words: the hashtags are nodes, and the edges are whether the hashtags\n",
        "were used together. As a first step, let’s get some info on the most\n",
        "popular hashtags:"
      ],
      "id": "73f8c9ea-3ab8-4d5b-873f-222c3c92a2f3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract and count hashtags\n",
        "rstats_tags = []\n",
        "for idx, row in rstats_content.iterrows():\n",
        "    for tag in row['tags']:\n",
        "        rstats_tags.append({\n",
        "            'cid': row['cid'],\n",
        "            'hashtag': tag.lower()\n",
        "        })\n",
        "\n",
        "rstats_tags_df = pd.DataFrame(rstats_tags)\n",
        "rstats_tags_count = rstats_tags_df['hashtag'].value_counts().reset_index()\n",
        "rstats_tags_count.columns = ['hashtag', 'n']\n",
        "\n",
        "# Plot top hashtags\n",
        "plt.figure(figsize=(10, 8))\n",
        "top_hashtags = rstats_tags_count.head(10)\n",
        "plt.barh(range(len(top_hashtags)), top_hashtags['n'])\n",
        "plt.yticks(range(len(top_hashtags)), top_hashtags['hashtag'])\n",
        "plt.xlabel('Count')\n",
        "plt.title('Top Hashtags in #rstats Posts')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "3951596c-3a7b-4e13-8f1e-80871214344e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, to find co-occurrence of hashtags. You could also do this with\n",
        "words, but it often comes out less meaningful."
      ],
      "id": "bf8c6367-119c-418e-ba44-eef6a81351de"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cooccurrence_pairs = []\n",
        "for cid in rstats_tags_df['cid'].unique():\n",
        "    post_tags = rstats_tags_df[rstats_tags_df['cid'] == cid]['hashtag'].tolist()\n",
        "    if len(post_tags) > 1:\n",
        "        for pair in combinations(post_tags, 2):\n",
        "            cooccurrence_pairs.append({'from': pair[0], 'to': pair[1]})\n",
        "            cooccurrence_pairs.append({'from': pair[1], 'to': pair[0]})  # Undirected\n",
        "\n",
        "rstats_tags_cooc = pd.DataFrame(cooccurrence_pairs)\n",
        "print(f\"Co-occurrence pairs: {len(rstats_tags_cooc)}\")\n",
        "print(rstats_tags_cooc.head())"
      ],
      "id": "9ec3852e-6e46-4cf6-80a5-47660903938b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now you should notice this looks like a network already. Let’s make it\n",
        "one:"
      ],
      "id": "5a8e3631-65d9-4eb6-b12b-6aebf09174c8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create hashtag network\n",
        "hashtag_network = nx.from_pandas_edgelist(rstats_tags_cooc, 'from', 'to')\n",
        "\n",
        "# Add node attributes (counts)\n",
        "hashtag_counts_dict = dict(zip(rstats_tags_count['hashtag'], rstats_tags_count['n']))\n",
        "nx.set_node_attributes(hashtag_network, hashtag_counts_dict, 'count')\n",
        "\n",
        "print(f\"Hashtag network: {hashtag_network.number_of_nodes()} nodes, {hashtag_network.number_of_edges()} edges\")"
      ],
      "id": "b46482f8-20a4-4df6-a24f-71d26f300c6e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can try a few things to turn this into a nice plot. Let’s get a\n",
        "baseline first:"
      ],
      "id": "20da7a56-832c-46b1-a781-7717f96e8a29"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get top 50 hashtags for visualization\n",
        "top_50_hashtags = rstats_tags_count.head(50)['hashtag'].tolist()\n",
        "hashtag_subgraph = hashtag_network.subgraph(top_50_hashtags)\n",
        "\n",
        "plt.figure(figsize=(15, 12))\n",
        "pos = nx.spring_layout(hashtag_subgraph, k=2, iterations=50)\n",
        "\n",
        "# Draw network\n",
        "nx.draw_networkx_edges(hashtag_subgraph, pos, alpha=0.3, width=0.5)\n",
        "nx.draw_networkx_labels(hashtag_subgraph, pos, font_size=8)\n",
        "\n",
        "plt.title('Co-occurrence Network of #rstats Hashtags (Top 50)', fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "539b271f-f6e9-4ec8-950b-4c5ed9696eaf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use color to show the centrality of nodes. You can play around\n",
        "with which measure produces the most interesting visual."
      ],
      "id": "a8635340-29d4-4b35-aec2-5e0e3c2ebf73"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate centrality measures for hashtag network\n",
        "hashtag_centrality = {\n",
        "    'degree': nx.degree_centrality(hashtag_subgraph),\n",
        "    'closeness': nx.closeness_centrality(hashtag_subgraph),\n",
        "    'betweenness': nx.betweenness_centrality(hashtag_subgraph),\n",
        "    'eigenvector': nx.eigenvector_centrality(hashtag_subgraph, max_iter=1000)\n",
        "}\n",
        "\n",
        "# Create visualization with eigenvector centrality coloring\n",
        "plt.figure(figsize=(15, 12))\n",
        "pos = nx.spring_layout(hashtag_subgraph, k=2, iterations=50)\n",
        "\n",
        "# Color nodes by eigenvector centrality\n",
        "eigenvector_values = [hashtag_centrality['eigenvector'][node] for node in hashtag_subgraph.nodes()]\n",
        "nodes = nx.draw_networkx_nodes(hashtag_subgraph, pos, \n",
        "                              node_color=eigenvector_values, \n",
        "                              cmap='coolwarm', \n",
        "                              node_size=300)\n",
        "\n",
        "nx.draw_networkx_edges(hashtag_subgraph, pos, alpha=0.3, width=0.5)\n",
        "nx.draw_networkx_labels(hashtag_subgraph, pos, font_size=8)\n",
        "\n",
        "plt.colorbar(nodes, label='Eigenvector Centrality')\n",
        "plt.title('Hashtag Network Colored by Eigenvector Centrality', fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "db2c7535-cac1-40cd-99cd-ec5e0bf2877d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also see if we can find some communities in this data. As above,\n",
        "we are using the Louvain and Leiden algorithms:"
      ],
      "id": "1496b282-aa5a-4fef-a325-7f6f18e7261e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import networkx.algorithms.community as nx_comm\n",
        "\n",
        "louvain_communities = nx.community.louvain_communities(hashtag_subgraph, seed=42)\n",
        "# leiden_communities = nx.community.leiden_communities(hashtag_subgraph, seed=42) \n",
        "\n",
        "# Create community assignments\n",
        "louvain_dict = {}\n",
        "for i, community in enumerate(louvain_communities):\n",
        "    for node in community:\n",
        "        louvain_dict[node] = i\n",
        "\n",
        "leiden_dict = {}\n",
        "# for i, community in enumerate(leiden_communities):\n",
        "#     for node in community:\n",
        "#         leiden_dict[node] = i\n",
        "\n",
        "print(f\"Louvain found {len(louvain_communities)} communities\")\n",
        "# print(f\"Leiden found {len(leiden_communities)} communities\")"
      ],
      "id": "0007e1da-1463-46c4-8a57-ab81c36f3b2e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the network grouped by Louvain:"
      ],
      "id": "98fd7076-be73-43fa-84c0-48db2c4b4e51"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 12))\n",
        "pos = nx.spring_layout(hashtag_subgraph, k=2, iterations=50)\n",
        "\n",
        "# Color nodes by Louvain communities\n",
        "community_colors = plt.cm.Set3(np.linspace(0, 1, len(louvain_communities)))\n",
        "node_colors = [community_colors[louvain_dict.get(node, 0)] for node in hashtag_subgraph.nodes()]\n",
        "\n",
        "nx.draw_networkx_nodes(hashtag_subgraph, pos, node_color=node_colors, node_size=300)\n",
        "nx.draw_networkx_edges(hashtag_subgraph, pos, alpha=0.3, width=0.5)\n",
        "nx.draw_networkx_labels(hashtag_subgraph, pos, font_size=8)\n",
        "\n",
        "plt.title('Hashtag Network - Louvain Communities', fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "be1ee793-a55a-480c-92f8-43d42e60e313"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And here it is grouped by the Leiden algorithm:\n",
        "\n",
        "``` python\n",
        "plt.figure(figsize=(15, 12))\n",
        "pos = nx.spring_layout(hashtag_subgraph, k=2, iterations=50)\n",
        "\n",
        "# Color nodes by Leiden communities\n",
        "community_colors = plt.cm.Set1(np.linspace(0, 1, len(leiden_communities)))\n",
        "node_colors = [community_colors[leiden_dict.get(node, 0)] for node in hashtag_subgraph.nodes()]\n",
        "\n",
        "nx.draw_networkx_nodes(hashtag_subgraph, pos, node_color=node_colors, node_size=300)\n",
        "nx.draw_networkx_edges(hashtag_subgraph, pos, alpha=0.3, width=0.5)\n",
        "nx.draw_networkx_labels(hashtag_subgraph, pos, font_size=8)\n",
        "\n",
        "plt.title('Hashtag Network - Leiden Communities', fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "## Follower Network\n",
        "\n",
        "Within the #rstats content, we can also check the community that posts\n",
        "this content. We first get the user handles from the data:"
      ],
      "id": "ab8b5b1c-b905-4850-b67b-b72934f74101"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get unique users from rstats content\n",
        "rstats_users = rstats_content['author_handle'].unique()\n",
        "print(f\"Unique #rstats users: {len(rstats_users)}\")"
      ],
      "id": "0163fe9a-d957-4963-af66-7fa035dbaa5c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we query who follows these users who post about #rstats:"
      ],
      "id": "3d3ec090-9ab2-4121-af7f-84246a43245a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_followers_data(handle, limit=100):\n",
        "    \"\"\"Get followers for a given handle\"\"\"\n",
        "    try:\n",
        "        response = client.get_followers(handle, limit=limit)\n",
        "        followers = [follow.handle for follow in response.followers]\n",
        "        return followers\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting followers for {handle}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Save/load follower data\n",
        "follower_data_file = \"data/follower_data_py.pkl\"\n",
        "\n",
        "if not os.path.exists(follower_data_file):\n",
        "    follower_data = []\n",
        "    for user in tqdm(rstats_users[:50], desc=\"Getting followers\"):  # Limit for demo\n",
        "        followers = get_followers_data(user)\n",
        "        follower_data.append({\n",
        "            'author_handle': user,\n",
        "            'followed_by': followers\n",
        "        })\n",
        "    \n",
        "    follower_df = pd.DataFrame(follower_data)\n",
        "    with open(follower_data_file, 'wb') as f:\n",
        "        pickle.dump(follower_df, f)\n",
        "else:\n",
        "    with open(follower_data_file, 'rb') as f:\n",
        "        follower_df = pickle.load(f)\n",
        "\n",
        "print(f\"Follower data shape: {follower_df.shape}\")"
      ],
      "id": "19bddbc8-6796-47de-9aa7-ab39e5adee39"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Who follows the most accounts contributing to #rstats?"
      ],
      "id": "f0e574bd-206c-4dba-80bb-e4225ad59cf8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Who follows the most #rstats accounts?\n",
        "all_followers = []\n",
        "for idx, row in follower_df.iterrows():\n",
        "    for follower in row['followed_by']:\n",
        "        all_followers.append(follower)\n",
        "\n",
        "follower_counts = pd.Series(all_followers).value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(follower_counts)), follower_counts.values)\n",
        "plt.yticks(range(len(follower_counts)), follower_counts.index)\n",
        "plt.xlabel('Number of #rstats accounts followed')\n",
        "plt.title('Users who follow the most #rstats accounts')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "f9e71fc2-7351-4365-a0a3-f75658d19ad3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can turn this data into a directed network where the nodes are users\n",
        "and the edges are whether a user follows another:"
      ],
      "id": "2e3d0131-1cea-4591-bb0c-7a34a793bdb6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create follower network edges\n",
        "follower_edges = []\n",
        "for idx, row in follower_df.iterrows():\n",
        "    for follower in row['followed_by']:\n",
        "        follower_edges.append({\n",
        "            'from': follower,\n",
        "            'to': row['author_handle']\n",
        "        })\n",
        "\n",
        "follower_network_df = pd.DataFrame(follower_edges)\n",
        "follower_network = nx.from_pandas_edgelist(follower_network_df, 'from', 'to', create_using=nx.DiGraph())\n",
        "\n",
        "print(f\"Follower network: {follower_network.number_of_nodes()} nodes, {follower_network.number_of_edges()} edges\")"
      ],
      "id": "a4c8a6df-ebe5-412a-82ea-59acca43ca94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# not a good idea to actually run this, since networkX is so slow\n",
        "plt.figure(figsize=(15, 12))\n",
        "nx.draw_kamada_kawai(follower_network)\n",
        "plt.show()"
      ],
      "id": "17fef992-1402-4dac-9d60-87d63c4c60a3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a mess, since there are so many nodes in the network now. We can\n",
        "again look for the most central nodes (aka users) in this network:"
      ],
      "id": "ebe7bebc-78a2-451e-adf2-c935b80e1e45"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate centrality measures for follower network\n",
        "follower_centrality = {\n",
        "    'degree': nx.degree_centrality(follower_network),\n",
        "    'closeness': nx.closeness_centrality(follower_network),\n",
        "    'betweenness': nx.betweenness_centrality(follower_network),\n",
        "    'eigenvector': nx.eigenvector_centrality(follower_network, max_iter=1000)\n",
        "}\n",
        "\n",
        "# Create centrality dataframe\n",
        "follower_centrality_df = pd.DataFrame({\n",
        "    'name': list(follower_network.nodes()),\n",
        "    'degree': [follower_centrality['degree'][node] for node in follower_network.nodes()],\n",
        "    'closeness': [follower_centrality['closeness'][node] for node in follower_network.nodes()],\n",
        "    'betweenness': [follower_centrality['betweenness'][node] for node in follower_network.nodes()],\n",
        "    'eigenvector': [follower_centrality['eigenvector'][node] for node in follower_network.nodes()]\n",
        "})\n",
        "\n",
        "print(\"Most central users in follower network:\")\n",
        "print(follower_centrality_df.nlargest(10, 'degree')[['name', 'degree']])"
      ],
      "id": "ab173704-a024-4dd1-8b0d-05a6efad251d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let’s try only the most central accounts:"
      ],
      "id": "6ff889de-cb4e-4237-9661-28a3551f3f3d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize follower network (top 100 nodes by eigenvector centrality)\n",
        "top_100_nodes = follower_centrality_df.nlargest(100, 'eigenvector')['name'].tolist()\n",
        "most_central_nodes = follower_centrality_df.nlargest(5, 'eigenvector')['name'].tolist()\n",
        "\n",
        "follower_subgraph = follower_network.subgraph(top_100_nodes)\n",
        "\n",
        "plt.figure(figsize=(15, 12))\n",
        "pos = nx.spring_layout(follower_subgraph, k=1, iterations=50)\n",
        "\n",
        "# Draw edges\n",
        "nx.draw_networkx_edges(follower_subgraph, pos, alpha=0.3, width=0.5, edge_color='gray')\n",
        "\n",
        "# Draw nodes\n",
        "nx.draw_networkx_nodes(follower_subgraph, pos, node_color='firebrick', node_size=50, alpha=0.8)\n",
        "\n",
        "# Add labels for most central nodes\n",
        "labels = {node: node if node in most_central_nodes else '' for node in follower_subgraph.nodes()}\n",
        "nx.draw_networkx_labels(follower_subgraph, pos, labels, font_size=8)\n",
        "\n",
        "plt.title('Follower Network (#rstats users)', fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "759a6fb5-6216-432a-bd36-10366c9696d7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mention Network\n",
        "\n",
        "We can also contruct a network with users as nodes and mentions as the\n",
        "edges. For this, let’s extract mentions first:"
      ],
      "id": "6d07066c-c6d9-479e-99bb-cf096e3fcaf1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract mentions from rstats content\n",
        "mention_pattern = r'@(\\w+)'\n",
        "mention_edges = []\n",
        "\n",
        "for idx, row in rstats_content.iterrows():\n",
        "    if '@' in row['text']:\n",
        "        mentions = re.findall(mention_pattern, row['text'])\n",
        "        for mention in mentions:\n",
        "            mention_edges.append({\n",
        "                'from': row['author_handle'],\n",
        "                'to': f\"@{mention}\"\n",
        "            })\n",
        "\n",
        "mentions_df = pd.DataFrame(mention_edges)\n",
        "print(f\"Mention edges: {len(mentions_df)}\")\n",
        "print(mentions_df.head())"
      ],
      "id": "2fa5ff42-830e-490f-8f1c-f145423a1384"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s see who is mentioned most:"
      ],
      "id": "ca999788-7851-4251-8051-edfec082b817"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Who is mentioned most?\n",
        "mention_counts = mentions_df['to'].value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(mention_counts)), mention_counts.values)\n",
        "plt.yticks(range(len(mention_counts)), mention_counts.index)\n",
        "plt.xlabel('Mention Count')\n",
        "plt.title('Most Mentioned Users in #rstats Posts')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "e8dedf59-34ae-4461-9459-8fe99e6b2ed6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The network comes natural at this point:"
      ],
      "id": "904836a4-5152-4e97-9c50-2662b190b899"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and visualize mention network\n",
        "mention_network = nx.from_pandas_edgelist(mentions_df, 'from', 'to', create_using=nx.DiGraph())\n",
        "\n",
        "plt.figure(figsize=(15, 12))\n",
        "pos = nx.spring_layout(mention_network, k=1, iterations=50)\n",
        "\n",
        "nx.draw_networkx_edges(mention_network, pos, alpha=0.3, width=0.5, edge_color='gray')\n",
        "nx.draw_networkx_nodes(mention_network, pos, node_color='firebrick', node_size=30, alpha=0.8)\n",
        "\n",
        "plt.title('Mention Network in #rstats Posts', fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "e4c84c3b-71bc-483b-90e6-9910b32b3297"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Share/repost Network\n",
        "\n",
        "Another way to contruct a network from this data is by looking for\n",
        "reposts. Here the nodes would be posts"
      ],
      "id": "5e2f313e-a271-44a6-90f7-f61404ec9c5a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_reposts_data(uri, limit=100):\n",
        "    \"\"\"Get reposts for a specific post URI\"\"\"\n",
        "    try:\n",
        "        response = client.app.bsky.feed.get_reposted_by({\"uri\": uri, \"limit\": limit})\n",
        "        # reposts = response.reposted_by\n",
        "        reposts = [repost.handle for repost in response.reposted_by]\n",
        "        return reposts\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting reposts for {uri}: {e}\")\n",
        "        return []\n",
        "\n",
        "# Get repost data for posts with replies\n",
        "repost_data_file = \"data/repost_data_py.pkl\"\n",
        "\n",
        "if not os.path.exists(repost_data_file):\n",
        "    repost_data = []\n",
        "    posts_with_replies = rstats_content[rstats_content['reply_count'] > 0]\n",
        "    \n",
        "    for idx, row in tqdm(posts_with_replies.head(20).iterrows(), desc=\"Getting reposts\"):\n",
        "        reposts = get_reposts_data(row['uri'])\n",
        "        if reposts:\n",
        "            repost_data.append({\n",
        "                'uri': row['uri'],\n",
        "                'author_handle': row['author_handle'],\n",
        "                'reposted_by': reposts\n",
        "            })\n",
        "    \n",
        "    repost_df = pd.DataFrame(repost_data)\n",
        "    with open(repost_data_file, 'wb') as f:\n",
        "        pickle.dump(repost_df, f)\n",
        "else:\n",
        "    with open(repost_data_file, 'rb') as f:\n",
        "        repost_df = pickle.load(f)\n",
        "\n",
        "print(f\"Repost data shape: {repost_df.shape}\")"
      ],
      "id": "1df9861b-99a5-4701-92c5-3c13f725575a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create repost network edges\n",
        "repost_edges = []\n",
        "for idx, row in repost_df.iterrows():\n",
        "    for reposter in row['reposted_by']:\n",
        "        repost_edges.append({\n",
        "            'from': row['author_handle'],\n",
        "            'to': reposter\n",
        "        })\n",
        "\n",
        "repost_network_df = pd.DataFrame(repost_edges)\n",
        "repost_network = nx.from_pandas_edgelist(repost_network_df, 'from', 'to', create_using=nx.DiGraph())\n",
        "\n",
        "print(f\"Repost network: {repost_network.number_of_nodes()} nodes, {repost_network.number_of_edges()} edges\")"
      ],
      "id": "9b1bbbb3-ee6e-487a-952c-34610602a4d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "pos = nx.spring_layout(repost_network, k=1, iterations=50)\n",
        "\n",
        "nx.draw_networkx_edges(repost_network, pos, alpha=0.3, width=0.5, edge_color='gray')\n",
        "nx.draw_networkx_nodes(repost_network, pos, node_color='firebrick', node_size=50, alpha=0.8)\n",
        "\n",
        "plt.title('Repost Network (#rstats)', fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "edfc47e1-a7b2-4e5d-b090-78c449fd25f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s look at centrality again to see"
      ],
      "id": "fc88af4a-f067-4df5-b2d6-5a175099041b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate centrality for repost network\n",
        "repost_centrality = {\n",
        "    'degree': nx.degree_centrality(repost_network),\n",
        "    'closeness': nx.closeness_centrality(repost_network),\n",
        "    'betweenness': nx.betweenness_centrality(repost_network),\n",
        "    'eigenvector': nx.eigenvector_centrality(repost_network, max_iter=1000)\n",
        "}\n",
        "\n",
        "repost_centrality_df = pd.DataFrame({\n",
        "    'name': list(repost_network.nodes()),\n",
        "    'degree': [repost_centrality['degree'][node] for node in repost_network.nodes()],\n",
        "    'closeness': [repost_centrality['closeness'][node] for node in repost_network.nodes()],\n",
        "    'betweenness': [repost_centrality['betweenness'][node] for node in repost_network.nodes()],\n",
        "    'eigenvector': [repost_centrality['eigenvector'][node] for node in repost_network.nodes()]\n",
        "})\n",
        "\n",
        "print(\"Most central users in repost network:\")\n",
        "most_central_repost = repost_centrality_df.nlargest(5, 'degree')\n",
        "print(most_central_repost[['name', 'degree']])"
      ],
      "id": "9f282d64-dccd-4449-912b-e49d5678412e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s once again see which are the most central accounts:"
      ],
      "id": "6273be07-a5df-417e-b10e-88082e7b270a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize with top nodes highlighted\n",
        "top_100_repost = repost_centrality_df.nlargest(100, 'degree')['name'].tolist()\n",
        "most_central_names = most_central_repost['name'].tolist()\n",
        "\n",
        "if top_100_repost:\n",
        "    repost_subgraph = repost_network.subgraph(top_100_repost)\n",
        "    \n",
        "    plt.figure(figsize=(15, 12))\n",
        "    pos = nx.spring_layout(repost_subgraph, k=1, iterations=50)\n",
        "    \n",
        "    # Draw edges\n",
        "    nx.draw_networkx_edges(repost_subgraph, pos, alpha=0.3, width=0.5, edge_color='gray')\n",
        "    \n",
        "    # Draw nodes\n",
        "    nx.draw_networkx_nodes(repost_subgraph, pos, node_color='firebrick', node_size=50, alpha=0.8)\n",
        "    \n",
        "    # Add labels for most central nodes\n",
        "    labels = {node: node if node in most_central_names else '' for node in repost_subgraph.nodes()}\n",
        "    nx.draw_networkx_labels(repost_subgraph, pos, labels, font_size=8)\n",
        "    \n",
        "    plt.title('Repost Network with Central Users Highlighted', fontsize=16)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "id": "26f31485-9325-434e-9b18-0ae2f883fac9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let’s see if we can find any sensible communities in this network:"
      ],
      "id": "193f091e-9ca7-4c06-b8e3-694465c8d10a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Community detection for repost network\n",
        "if repost_network.number_of_nodes() > 0:\n",
        "    # Convert to undirected for community detection\n",
        "    repost_undirected = repost_network.to_undirected()\n",
        "    \n",
        "    if repost_undirected.number_of_nodes() > 1:\n",
        "        louvain_repost = nx_comm.louvain_communities(repost_undirected, seed=42)\n",
        "        \n",
        "        # Create community visualization\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        pos = nx.spring_layout(repost_undirected, k=1, iterations=50)\n",
        "        \n",
        "        # Color nodes by community\n",
        "        community_colors = plt.cm.Set3(np.linspace(0, 1, len(louvain_repost)))\n",
        "        louvain_repost_dict = {}\n",
        "        for i, community in enumerate(louvain_repost):\n",
        "            for node in community:\n",
        "                louvain_repost_dict[node] = i\n",
        "        \n",
        "        node_colors = [community_colors[louvain_repost_dict.get(node, 0)] \n",
        "                      for node in repost_undirected.nodes()]\n",
        "        \n",
        "        nx.draw_networkx_edges(repost_undirected, pos, alpha=0.3, width=0.5, edge_color='gray')\n",
        "        nx.draw_networkx_nodes(repost_undirected, pos, node_color=node_colors, node_size=50, alpha=0.8)\n",
        "        \n",
        "        # Add labels for most central nodes\n",
        "        labels = {node: node if node in most_central_names else '' for node in repost_undirected.nodes()}\n",
        "        nx.draw_networkx_labels(repost_undirected, pos, labels, font_size=8)\n",
        "        \n",
        "        plt.title('Repost Network with Louvain Communities', fontsize=16)\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"Found {len(louvain_repost)} communities in repost network\")\n",
        "    else:\n",
        "        print(\"Not enough nodes for community detection in repost network\")\n",
        "else:\n",
        "    print(\"No repost network data available\")"
      ],
      "id": "f1fd2345-31d6-4f15-836d-4f7995afedfa"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}